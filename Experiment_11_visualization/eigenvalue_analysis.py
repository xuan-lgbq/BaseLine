import torch
from hessian_utils import compute_hessian_eigenvalues_pyhessian_fixed  # ä½¿ç”¨ä¿®æ­£ç‰ˆæœ¬
from Top_k_Dom_search import search_top_k_dominant_space

def compute_and_analyze_eigenvalues(model, loss_function, single_loader, top_k, device, config, step):
    """è®¡ç®—å¹¶åˆ†æç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡"""
    try:
        # ä½¿ç”¨ä¿®æ­£ç‰ˆæœ¬è®¡ç®— Hessian ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
        eigenvalues, eigenvectors = compute_hessian_eigenvalues_pyhessian_fixed(
            model=model,
            criterion=loss_function,
            data_loader=single_loader,
            top_k=top_k,
            device=device
        )
        
        # éªŒè¯æ•°æ®
        print(f"ğŸ“Š Step {step}: éªŒè¯è®¡ç®—ç»“æœ")
        print(f"   ç‰¹å¾å€¼æ•°æ®ç±»å‹: {type(eigenvalues)}, å½¢çŠ¶: {eigenvalues.shape}")
        print(f"   ç‰¹å¾å‘é‡æ•°æ®ç±»å‹: {type(eigenvectors)}, å½¢çŠ¶: {eigenvectors.shape}")
        print(f"   ç‰¹å¾å€¼è®¾å¤‡: {eigenvalues.device}")
        print(f"   ç‰¹å¾å‘é‡è®¾å¤‡: {eigenvectors.device}")
        
        # ç‰¹å¾å€¼æ’åºéªŒè¯
        is_descending = torch.all(eigenvalues[:-1] >= eigenvalues[1:])
        print(f"   æ˜¯å¦é™åº: {is_descending}")
        print(f"   å‰5ä¸ªç‰¹å¾å€¼: {eigenvalues[:5]}")

        # ğŸ”§ ä¿®æ­£ï¼šå°†CUDA tensorè½¬æ¢ä¸ºCPUä¸Šçš„Pythonåˆ—è¡¨
        eigenvalues_cpu_list = eigenvalues.cpu().tolist()
        print(f"ğŸ”§ è½¬æ¢ä¸ºCPUåˆ—è¡¨: {eigenvalues_cpu_list[:5]}")
        
        # è®¡ç®—dominant dimension
        dominant_dim, gaps = search_top_k_dominant_space(eigenvalues_cpu_list, method=config["method"])
        
        # å–å‰ dominant_dim ä¸ªç‰¹å¾å‘é‡
        eigenvectors_dominant = eigenvectors[:, :dominant_dim]
        eigenvalues_dominant = eigenvalues[:dominant_dim]
        
        print(f"ğŸ“Š Step {step}: è®¡ç®—æˆåŠŸ, Dominant Dimension: {dominant_dim}")
        print(f"ğŸ“Š Step {step}: å‰{dominant_dim}ä¸ªç‰¹å¾å€¼: {eigenvalues_dominant}")
        print(f"ğŸ“Š Step {step}: ç‰¹å¾å‘é‡çŸ©é˜µå½¢çŠ¶: {eigenvectors_dominant.shape}")
        print(f"ğŸ“Š Step {step}: Gapså‰5ä¸ª: {gaps[:5] if len(gaps) >= 5 else gaps}")
        
        return eigenvalues, eigenvectors_dominant, dominant_dim, gaps, True
        
    except Exception as e:
        print(f"âš ï¸  Step {step}: è®¡ç®— Hessian ç‰¹å¾å€¼å¤±è´¥: {e}")
        import traceback
        print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return None, None, None, None, False

def collect_eigenvalue_data(eigenvalue_history, eigenvalues):
    """æ”¶é›†ç‰¹å¾å€¼æ•°æ®"""
    for i, eigenval in enumerate(eigenvalues):
        # ç¡®ä¿eigenvalæ˜¯tensorï¼Œç„¶åè½¬æ¢ä¸ºPythonæ ‡é‡
        if isinstance(eigenval, torch.Tensor):
            raw_eigenval = eigenval.cpu().item()
        else:
            raw_eigenval = float(eigenval)
        eigenvalue_history[f"top_{i+1}"].append(raw_eigenval)

def prepare_wandb_log(eigenvalues, dominant_dim, gaps):
    """å‡†å¤‡wandbè®°å½•æ•°æ®"""
    hessian_eigenvals = {}
    for i, eigenval in enumerate(eigenvalues):
        # ç¡®ä¿eigenvalæ˜¯tensorï¼Œç„¶åè½¬æ¢ä¸ºPythonæ ‡é‡
        if isinstance(eigenval, torch.Tensor):
            raw_eigenval = eigenval.cpu().item()
        else:
            raw_eigenval = float(eigenval)
        hessian_eigenvals[f"Raw_Hessian_Eigenvalues/Top_{i+1}"] = raw_eigenval
    
    # ç¡®ä¿gapsæ˜¯Pythonåˆ—è¡¨
    if isinstance(gaps, torch.Tensor):
        gaps_list = gaps.cpu().tolist()
    elif isinstance(gaps, list):
        gaps_list = gaps
    else:
        gaps_list = [float(g) for g in gaps]
    
    wandb_data = {
        "Dominant Dimension": dominant_dim,
        "Gaps": gaps_list[:5] if len(gaps_list) >= 5 else gaps_list
    }
    wandb_data.update(hessian_eigenvals)
    
    return wandb_data