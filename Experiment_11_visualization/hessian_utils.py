import torch
import numpy as np
from config_linear import device
from pyhessian import hessian

# è®¡ç®— Hessian çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
def compute_hessian_eigen(loss, params, top_k = 832):  # previously top_k = 5
    params = list(params)
    
    # è·å–æ‰€æœ‰å‚æ•°çš„å±•å¹³æ¢¯åº¦
    grads_flat = []
    for p in params:
        g = torch.autograd.grad(loss, p, create_graph=True, retain_graph=True)[0]
        grads_flat.append(g.view(-1))  # æ¯ä¸ªå‚æ•°å±•å¹³ä¸ºå‘é‡
    grads_flat = torch.cat(grads_flat)  # å½¢çŠ¶: (total_params,)
    total_params = grads_flat.size(0)   # æ€»å‚æ•°é‡ p = 75
    
    # è®¡ç®—HessiançŸ©é˜µ
    hessian_rows = []
    for g in grads_flat:  # éå†æ¯ä¸ªæ¢¯åº¦å…ƒç´ 
        # è®¡ç®—äºŒé˜¶å¯¼æ•°ï¼ˆHessianè¡Œï¼‰
        hessian_row = torch.autograd.grad(
            outputs=g, 
            inputs=params, 
            retain_graph=True, 
            allow_unused=True
        )
        # å¤„ç†æœªä½¿ç”¨çš„å‚æ•°æ¢¯åº¦ï¼ˆå¡«å……é›¶ï¼‰
        hessian_row_flat = []
        for h, p in zip(hessian_row, params):
            if h is None:
                h_flat = torch.zeros_like(p).view(-1)
            else:
                h_flat = h.view(-1)
            hessian_row_flat.append(h_flat)
        hessian_row_flat = torch.cat(hessian_row_flat)  # å½¢çŠ¶: (total_params,)
        hessian_rows.append(hessian_row_flat)
    
    # æ„å»ºHessiançŸ©é˜µ
    hessian_matrix = torch.stack(hessian_rows)  # å½¢çŠ¶: (total_params, total_params)
    
    # è½¬æ¢ä¸ºNumPyå¹¶è®¡ç®—ç‰¹å¾å€¼/å‘é‡
    hessian_numpy = hessian_matrix.detach().cpu().numpy()
    eigenvalues, eigenvectors = np.linalg.eigh(hessian_numpy)
    sorted_indices = np.argsort(-eigenvalues)  # é™åºæ’åˆ—
    return eigenvalues[sorted_indices], eigenvectors[:, sorted_indices][:, :top_k]

def flatten_eigenvector_list(eigenvector_list):
    """
    å°†PyHessianè¿”å›çš„åµŒå¥—tensoråˆ—è¡¨å±•å¹³ä¸ºå•ä¸ªtensor
    
    Args:
        eigenvector_list: å½¢å¦‚ [tensor1, tensor2, tensor3] çš„åˆ—è¡¨
    
    Returns:
        torch.Tensor: å±•å¹³åçš„ç‰¹å¾å‘é‡
    """
    flattened_parts = []
    for tensor_part in eigenvector_list:
        if isinstance(tensor_part, torch.Tensor):
            flattened_parts.append(tensor_part.view(-1))
        else:
            flattened_parts.append(torch.tensor(tensor_part).view(-1))
    
    return torch.cat(flattened_parts)

def process_pyhessian_eigenvectors(eigenvectors_matrix, eigenvalues_list):
    """
    å¤„ç†PyHessianè¿”å›çš„ç‰¹å¾å‘é‡æ ¼å¼
    
    Args:
        eigenvectors_matrix: PyHessianè¿”å›çš„ç‰¹å¾å‘é‡ï¼ˆåµŒå¥—åˆ—è¡¨æ ¼å¼ï¼‰
        eigenvalues_list: å¯¹åº”çš„ç‰¹å¾å€¼
    
    Returns:
        tuple: (eigenvalues_tensor, eigenvectors_tensor)
    """
    print(f"ğŸ” å¤„ç†PyHessianç‰¹å¾å‘é‡...")
    print(f"   eigenvectors_matrix ç±»å‹: {type(eigenvectors_matrix)}")
    print(f"   eigenvectors_matrix é•¿åº¦: {len(eigenvectors_matrix)}")
    
    if isinstance(eigenvectors_matrix, list) and len(eigenvectors_matrix) > 0:
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç»“æ„
        first_eigenvector = eigenvectors_matrix[0]
        print(f"   ç¬¬ä¸€ä¸ªç‰¹å¾å‘é‡ç±»å‹: {type(first_eigenvector)}")
        
        if isinstance(first_eigenvector, list):
            print(f"   ç¬¬ä¸€ä¸ªç‰¹å¾å‘é‡åŒ…å« {len(first_eigenvector)} ä¸ªéƒ¨åˆ†")
            for i, part in enumerate(first_eigenvector):
                print(f"     éƒ¨åˆ† {i}: ç±»å‹={type(part)}, å½¢çŠ¶={getattr(part, 'shape', 'N/A')}")
            
            # å¤„ç†åµŒå¥—åˆ—è¡¨æ ¼å¼
            num_eigenvectors = len(eigenvectors_matrix)
            flattened_eigenvectors = []
            
            for i, eigenvector_list in enumerate(eigenvectors_matrix):
                flattened_vec = flatten_eigenvector_list(eigenvector_list)
                flattened_eigenvectors.append(flattened_vec)
                print(f"   ç‰¹å¾å‘é‡ {i+1}: å±•å¹³åå½¢çŠ¶ {flattened_vec.shape}")
            
            # å †å ä¸ºçŸ©é˜µ (total_params, num_eigenvectors)
            eigenvectors_tensor = torch.stack(flattened_eigenvectors, dim=1)
            
        elif isinstance(first_eigenvector, torch.Tensor):
            # å¦‚æœæ˜¯tensoråˆ—è¡¨ï¼Œç›´æ¥å †å 
            eigenvectors_tensor = torch.stack(eigenvectors_matrix, dim=1)
        else:
            # å…¶ä»–æ ¼å¼ï¼Œå°è¯•è½¬æ¢
            eigenvectors_tensor = torch.tensor(eigenvectors_matrix, dtype=torch.float32)
    
    else:
        # å¦‚æœä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼ŒæŒ‰åŸæ¥çš„æ–¹å¼å¤„ç†
        if isinstance(eigenvectors_matrix, torch.Tensor):
            eigenvectors_tensor = eigenvectors_matrix.clone().detach()
        elif isinstance(eigenvectors_matrix, np.ndarray):
            eigenvectors_tensor = torch.from_numpy(eigenvectors_matrix)
        else:
            eigenvectors_tensor = torch.tensor(eigenvectors_matrix, dtype=torch.float32)
    
    # å¤„ç†ç‰¹å¾å€¼
    if isinstance(eigenvalues_list, torch.Tensor):
        eigenvalues_tensor = eigenvalues_list.clone().detach()
    elif isinstance(eigenvalues_list, (list, np.ndarray)):
        eigenvalues_tensor = torch.tensor(eigenvalues_list, dtype=torch.float32)
    else:
        eigenvalues_tensor = torch.tensor(eigenvalues_list, dtype=torch.float32)
    
    print(f"âœ… å¤„ç†å®Œæˆ:")
    print(f"   eigenvalues_tensor: {eigenvalues_tensor.shape}")
    print(f"   eigenvectors_tensor: {eigenvectors_tensor.shape}")
    
    return eigenvalues_tensor, eigenvectors_tensor

# This a function when running in remote, please check the input agruments before run.
# Function to compute the eigenvalues and eigenvectors of the Hessian matrix (using pyhessian)
def compute_hessian_eigen_pyhessian(model, criterion, data_loader, top_k=5, device=device):
    """
    Computes the top eigenvalues and eigenvectors of the Hessian matrix using the pyhessian library.

    Args:
        model: PyTorch model.
        criterion: Loss function.
        data_loader: Data loader used for computing the Hessian.
        top_k: The number of top eigenvalues and eigenvectors to return.
        device: The computation device (CPU or CUDA).

    Returns:
        tuple: Contains two NumPy arrays:
            - eigenvalues: Top k eigenvalues in descending order (shape: (top_k,)).
            - eigenvectors: Corresponding eigenvectors (shape: (total_params, top_k)).
    """
    hessian_computer = hessian(model=model, criterion=criterion, data=data_loader, cuda='cuda')
    hessian_eigen = hessian_computer.eigenvalues(top_n=top_k)
    eigenvalues = np.array(hessian_eigen[0])
    eigenvectors = np.array(hessian_eigen[1])
    return eigenvalues, eigenvectors

def compute_layer_weight_eigenvalues(model, top_k=None):
    """
    è®¡ç®—æ¨¡å‹æ¯ä¸€å±‚æƒé‡çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
    
    Args:
        model: PyTorchæ¨¡å‹
        top_k: è¿”å›å‰kä¸ªç‰¹å¾å€¼ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰ç‰¹å¾å€¼
    
    Returns:
        dict: åŒ…å«æ¯å±‚ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„å­—å…¸
    """
    layer_eigenvalues = {}
    layer_eigenvectors = {}
    
    for name, param in model.named_parameters():
        # ä¿®æ”¹æ¡ä»¶ï¼šåŒ¹é… W1, W2, W3 å‚æ•°åï¼Œå¹¶ä¸”æ˜¯2ç»´çŸ©é˜µ
        if name in ['W1', 'W2', 'W3'] and param.dim() == 2:
            weight_matrix = param.detach().cpu().numpy()
            
            # å¦‚æœä¸æ˜¯æ–¹é˜µï¼Œä½¿ç”¨ W @ W.T æ¥è®¡ç®—ç‰¹å¾å€¼
            if weight_matrix.shape[0] != weight_matrix.shape[1]:
                # å¯¹äºéæ–¹é˜µï¼Œè®¡ç®— W @ W.T çš„ç‰¹å¾å€¼
                gram_matrix = np.dot(weight_matrix, weight_matrix.T)
                eigenvals, eigenvecs = np.linalg.eigh(gram_matrix)
            else:
                # å¯¹äºæ–¹é˜µï¼Œç›´æ¥è®¡ç®—ç‰¹å¾å€¼
                eigenvals, eigenvecs = np.linalg.eigh(weight_matrix)
            
            # æŒ‰é™åºæ’åˆ—
            sorted_indices = np.argsort(-eigenvals)
            eigenvals = eigenvals[sorted_indices]
            eigenvecs = eigenvecs[:, sorted_indices]
            
            # å¦‚æœæŒ‡å®šäº†top_kï¼Œåªè¿”å›å‰kä¸ª
            if top_k is not None:
                eigenvals = eigenvals[:top_k]
                eigenvecs = eigenvecs[:, :top_k]
            
            layer_eigenvalues[name] = eigenvals
            layer_eigenvectors[name] = eigenvecs
    
    return layer_eigenvalues, layer_eigenvectors

def compute_hessian_eigenvalues_pyhessian_fixed(model, criterion, data_loader, top_k=5, device='cuda'):
    """
    ä¿®æ­£ç‰ˆæœ¬ï¼šå¤„ç†PyHessiançš„åµŒå¥—tensoræ ¼å¼
    """
    try:
        # è®¡ç®—æ¨¡å‹å‚æ•°æ€»æ•°
        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"ğŸ” æ¨¡å‹å‚æ•°æ€»æ•°: {total_params}")
        
        # è‡ªåŠ¨è°ƒæ•´top_k
        actual_top_k = min(top_k, total_params)
        if actual_top_k != top_k:
            print(f"âš ï¸  è­¦å‘Š: è¯·æ±‚çš„top_k={top_k} è¶…è¿‡å‚æ•°æ€»æ•°={total_params}")
            print(f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´ä¸º top_k={actual_top_k}")
        
        hessian_computer = hessian(model=model, 
                                  criterion=criterion, 
                                  dataloader=data_loader,
                                  cuda=device.type=='cuda' if hasattr(device, 'type') else 'cuda' in str(device))

        print(f"ğŸ” å¼€å§‹è®¡ç®—å‰{actual_top_k}ä¸ªç‰¹å¾å€¼/ç‰¹å¾å‘é‡...")
        
        # ä½¿ç”¨è°ƒæ•´åçš„top_k
        result = hessian_computer.eigenvalues(
            maxIter=200, 
            tol=1e-6, 
            top_n=actual_top_k
        )
        
        if isinstance(result, tuple) and len(result) == 2:
            eigenvalues_list, eigenvectors_matrix = result
        else:
            raise ValueError(f"PyHessianè¿”å›æ ¼å¼å¼‚å¸¸: {type(result)}")
        
        print(f"ğŸ” PyHessianåŸå§‹è¿”å›:")
        print(f"   eigenvalues_list: {type(eigenvalues_list)}")
        print(f"   eigenvectors_matrix: {type(eigenvectors_matrix)}")
        
        # ä½¿ç”¨æ–°çš„å¤„ç†å‡½æ•°
        eigenvalues_tensor, eigenvectors_tensor = process_pyhessian_eigenvectors(
            eigenvectors_matrix, eigenvalues_list
        )
        
        # ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        eigenvalues_tensor = eigenvalues_tensor.to(device)
        eigenvectors_tensor = eigenvectors_tensor.to(device)
        
        # ç¡®ä¿ç‰¹å¾å€¼ä»å¤§åˆ°å°æ’åº
        eigenvalues_sorted, sort_indices = torch.sort(eigenvalues_tensor, descending=True)
        eigenvectors_sorted = eigenvectors_tensor[:, sort_indices]
        
        print(f"âœ… æœ€ç»ˆç»“æœ:")
        print(f"   ç‰¹å¾å€¼å½¢çŠ¶: {eigenvalues_sorted.shape}")
        print(f"   ç‰¹å¾å‘é‡å½¢çŠ¶: {eigenvectors_sorted.shape}")
        print(f"   å‰3ä¸ªç‰¹å¾å€¼: {eigenvalues_sorted[:3]}")
        
        return eigenvalues_sorted, eigenvectors_sorted
        
    except Exception as e:
        print(f"âŒ PyHessianè®¡ç®—å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise e

def debug_model_parameters(model):
    """è°ƒè¯•å‡½æ•°ï¼šæ£€æŸ¥æ¨¡å‹å‚æ•°è¯¦æƒ…"""
    print("ğŸ” æ¨¡å‹å‚æ•°è¯¦æƒ…:")
    total_params = 0
    for i, (name, param) in enumerate(model.named_parameters()):
        if param.requires_grad:
            param_count = param.numel()
            print(f"  {i}: {name} - å½¢çŠ¶: {param.shape}, å‚æ•°æ•°: {param_count}")
            total_params += param_count
    
    print(f"ğŸ“Š æ€»å‚æ•°æ•°: {total_params}")
    return total_params

def compute_dominant_projection_matrix(top_eigenvectors, k):
    """
    æ ¹æ®ç‰¹å¾å‘é‡æ„é€ æŠ•å½±çŸ©é˜µ P_k = Î£ u_i u_i^T
    Args:
        top_eigenvectors: å½¢çŠ¶ä¸º (p, k) çš„çŸ©é˜µï¼Œæ¯åˆ—æ˜¯ç‰¹å¾å‘é‡
    Returns:
        P_k: å½¢çŠ¶ä¸º (p, p) çš„æŠ•å½±çŸ©é˜µ
    """
    p = top_eigenvectors.shape[0]
    P_k = np.zeros((p, p))
    for i in range(k):
        u_i = top_eigenvectors[:, i].reshape(-1, 1)
        P_k += np.dot(u_i, u_i.T)  # ç´¯åŠ å¤–ç§¯
    return torch.from_numpy(P_k).float().to(device)  # è½¬ä¸ºTensorå¹¶æŒ‡å®šè®¾å¤‡