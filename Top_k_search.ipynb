{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depricate previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dictionary of top k eigenvectors for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 特征矩阵:\n",
      " [[-0.20433962  0.01774928 -0.21280398  0.35336356  0.21267685]\n",
      " [ 0.0963199  -0.52254612 -0.37396241 -0.200287   -0.09229253]\n",
      " [ 0.19064203  0.18541408 -0.13898791 -0.56814509  0.1919557 ]\n",
      " [ 0.23131538  0.37702749 -0.16801856 -0.27        0.05892778]\n",
      " [-0.60294259 -0.00950348  0.13019713 -0.53376948 -0.02739447]\n",
      " [-0.04563164  0.38436437 -0.1200868  -0.23065281 -0.40864833]\n",
      " [ 0.24753171 -0.59366849 -0.09533138 -0.268181   -0.06648195]\n",
      " [ 0.50223399  0.00085284  0.67768789 -0.10739636  0.16728233]\n",
      " [-0.3037924  -0.10161923  0.12161616 -0.12750935  0.73237177]\n",
      " [ 0.29613147  0.1987628  -0.5027993   0.03881013  0.41160129]] \n",
      "\n",
      "Epoch 1 特征矩阵:\n",
      " [[-0.20433962  0.01774928 -0.21280398  0.35336356  0.02923768]\n",
      " [ 0.0963199  -0.52254612 -0.37396241 -0.200287    0.13338619]\n",
      " [ 0.19064203  0.18541408 -0.13898791 -0.56814509 -0.61109847]\n",
      " [ 0.23131538  0.37702749 -0.16801856 -0.27        0.15475094]\n",
      " [-0.60294259 -0.00950348  0.13019713 -0.53376948  0.34686508]\n",
      " [-0.04563164  0.38436437 -0.1200868  -0.23065281  0.21092591]\n",
      " [ 0.24753171 -0.59366849 -0.09533138 -0.268181    0.07028444]\n",
      " [ 0.50223399  0.00085284  0.67768789 -0.10739636  0.33647933]\n",
      " [-0.3037924  -0.10161923  0.12161616 -0.12750935  0.16150016]\n",
      " [ 0.29613147  0.1987628  -0.5027993   0.03881013  0.52432663]] \n",
      "\n",
      "Epoch 2 特征矩阵:\n",
      " [[-0.20433962  0.01774928 -0.21280398 -0.50690303  0.3293446 ]\n",
      " [ 0.0963199  -0.52254612 -0.37396241 -0.48740375  0.05050519]\n",
      " [ 0.19064203  0.18541408 -0.13898791  0.34341024  0.24090064]\n",
      " [ 0.23131538  0.37702749 -0.16801856 -0.13961528  0.31526276]\n",
      " [-0.60294259 -0.00950348  0.13019713 -0.14564837  0.01059847]\n",
      " [-0.04563164  0.38436437 -0.1200868  -0.09370495  0.54214037]\n",
      " [ 0.24753171 -0.59366849 -0.09533138  0.32525482  0.42284315]\n",
      " [ 0.50223399  0.00085284  0.67768789 -0.4505318   0.03699861]\n",
      " [-0.3037924  -0.10161923  0.12161616 -0.04263773 -0.00554386]\n",
      " [ 0.29613147  0.1987628  -0.5027993  -0.16577768 -0.50728016]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置 NumPy 随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_eigenvector_dict():\n",
    "    num_epochs = 3  # 迭代次数\n",
    "    dim = 10  # 向量维度\n",
    "    num_vectors = 5  # 始终保持 5 个特征向量\n",
    "    recorded_steps_top_eigenvectors = {}\n",
    "\n",
    "    # 生成一个初始的正交基（使用 QR 分解确保正交）\n",
    "    base_vectors, _ = np.linalg.qr(np.random.randn(dim, num_vectors))  # 10 × 5 的正交矩阵\n",
    "    \n",
    "    for k in range(num_epochs):\n",
    "        if k == 0:\n",
    "            recorded_steps_top_eigenvectors[k] = base_vectors.copy()\n",
    "        else:\n",
    "            # 计算要保留的列数\n",
    "            num_shared = max(num_vectors - k, 0)    # 计算需要保留的特征向量数量\n",
    "            num_new = num_vectors - num_shared  # 计算需要替换的特征向量数量\n",
    "            \n",
    "            # 继承前一个 epoch 的部分特征向量\n",
    "            shared_vectors = recorded_steps_top_eigenvectors[k-1][:, :num_shared] if num_shared > 0 else np.empty((dim, 0))\n",
    "            \n",
    "            # 生成新的特征向量\n",
    "            new_vectors = np.random.randn(dim, num_new)\n",
    "            \n",
    "            # 组合最终的特征矩阵\n",
    "            recorded_steps_top_eigenvectors[k], _ = np.linalg.qr(np.hstack((shared_vectors, new_vectors)))  # QR分解，前几列已经正交，不会改变\n",
    "\n",
    "    return recorded_steps_top_eigenvectors\n",
    "\n",
    "# 生成特征向量字典\n",
    "recorded_steps_top_eigenvectors = generate_eigenvector_dict()\n",
    "\n",
    "# 打印前 ? 个 epoch 的特征矩阵\n",
    "for epoch in range(3):\n",
    "    print(f\"Epoch {epoch} 特征矩阵:\\n\", recorded_steps_top_eigenvectors[epoch], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(recorded_steps_top_eigenvectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Down Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import wraps\n",
    "# Binary Search for initial k_0\n",
    "def Binary_Search(previous, current, k_0, tau=0.98):\n",
    "    # tau = 0.95\n",
    "    # Lower and upper bounds for k\n",
    "    left, right = 0, k_0 - 1\n",
    "    \n",
    "    while left < right:\n",
    "        mid = left + (right - left + 1) // 2  # 取较大中点，防止死循环\n",
    "        matrix = np.matmul(previous[:, :mid].T, current[:, :mid])\n",
    "        _, sigma, _ = np.linalg.svd(matrix)\n",
    "        \n",
    "        # Check if all singular values are within [0, 1]\n",
    "        assert np.all((sigma >= -0.001) & (sigma <= 1.001)), \"Eigenvectors are not ortho-normalized!\"\n",
    "    \n",
    "        if np.min(sigma) < tau:\n",
    "            right = mid - 1\n",
    "        else:\n",
    "            left = mid  \n",
    "    \n",
    "    return left + 1\n",
    "\n",
    "# Define a decorator\n",
    "def optimize_k0(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(recorded_steps_top_eigenvectors, tau=0.98, k_0=None):\n",
    "        sorted_steps = sorted(recorded_steps_top_eigenvectors.keys())\n",
    "            \n",
    "        if len(sorted_steps) < 2:\n",
    "            raise ValueError(\"At least two recorded steps are required for Top-K search.\")\n",
    "        \n",
    "        if k_0 is None:\n",
    "        # 选择 epoch_0 和 epoch_1\n",
    "            epoch_0 = recorded_steps_top_eigenvectors[sorted_steps[0]]\n",
    "            epoch_1 = recorded_steps_top_eigenvectors[sorted_steps[1]]\n",
    "            k_0 = epoch_0.shape[1]  # 先给 k_0 赋值\n",
    "        \n",
    "            # 计算初始 k_0\n",
    "            optimized_k0 = Binary_Search(epoch_0, epoch_1, k_0, tau)\n",
    "        else:\n",
    "            optimized_k0 = k_0  # 直接使用提供的 k_0\n",
    "            \n",
    "        # 调用被装饰的 Top_Down 方法，并传入优化后的 k_0\n",
    "        return func(recorded_steps_top_eigenvectors, optimized_k0, sorted_steps, tau)\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "# Use the decorator\n",
    "@optimize_k0\n",
    "\n",
    "def Top_Down(recorded_steps_top_eigenvectors, tau=0.98, k_0=None, sorted_steps=None):\n",
    "    if sorted_steps is None:  \n",
    "        sorted_steps = sorted(recorded_steps_top_eigenvectors.keys())\n",
    "        \n",
    "    num_steps = len(sorted_steps) \n",
    "    # tau = 0.95 # Tolerance \n",
    "    k = int(k_0)  # Initialize k\n",
    "    trajectory = {}\n",
    "    trajectory[0] = k_0\n",
    "    trajectory[1] = k_0 \n",
    "    \n",
    "    for i in range(2, num_steps):\n",
    "        current_step = sorted_steps[i]\n",
    "        current = recorded_steps_top_eigenvectors[current_step][:, :k]   # Current top k eigenvectors\n",
    "        \n",
    "        previous_step = sorted_steps[i - 1]\n",
    "        previous = recorded_steps_top_eigenvectors[previous_step][:,:k]  # Previous top k eigenvectors\n",
    "            \n",
    "        for d in range(trajectory[i-1]):\n",
    "                \n",
    "            current_subspace = current[:, :trajectory[i-1]-d]  # Current subspace, top k-d eigenvectors\n",
    "            previous_subspace = previous[:, :trajectory[i-1]-d]  # Previous subspace, top k-d eigenvectors\n",
    "                \n",
    "            # Compute the similarity between the current and previous subspaces\n",
    "            matrix = np.matmul(current_subspace.T, previous_subspace)\n",
    "            _, sigma, _ = np.linalg.svd(matrix)\n",
    "                \n",
    "            # Check if all singular values are within [0, 1]\n",
    "            assert np.all((sigma >= -0.001) & (sigma <= 1.001)), \"Eigenvectors are not ortho-normalized!\"\n",
    "                \n",
    "            min_sigma = np.min(sigma)\n",
    "                \n",
    "            # If the minimal singular value is less then tau, then we reduce the dimensionality by d (one reduces dimension from top k to top k-d)\n",
    "                \n",
    "            # If the minimal singular value is greater than tau, which means the two subspaces are aligned, then we stop the loop and return the current k.\n",
    "            if min_sigma > tau:\n",
    "                trajectory[i] = trajectory[i-1] - d\n",
    "                break\n",
    "                \n",
    "            \n",
    "            \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5, 1: 5, 2: 3}\n"
     ]
    }
   ],
   "source": [
    "tau = 0.98\n",
    "k = Top_Down(recorded_steps_top_eigenvectors, tau, k_0=None)\n",
    "\n",
    "print(k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import wandb\n",
    "\n",
    "def Top_K_Search(recorded_steps_top_eigenvectors):\n",
    "    \n",
    "    sorted_steps = sorted(recorded_steps_top_eigenvectors.keys())  # Epoch\n",
    "    num_steps = len(sorted_steps)\n",
    "    \n",
    "    if num_steps < 2:\n",
    "        raise ValueError(\"At least two recorded steps are required for Top-K search.\")\n",
    "    \n",
    "    # Initialize k\n",
    "    k = recorded_steps_top_eigenvectors[sorted_steps[0]].shape[1]  # Number of columns\n",
    "    # k = k_0\n",
    "    tau = 0.98 # Tolerance\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        current_step = sorted_steps[i]\n",
    "        current = recorded_steps_top_eigenvectors[current_step][:, :k]   # Current top k eigenvectors\n",
    "        if i > 0:\n",
    "            previous_step = sorted_steps[i - 1]\n",
    "            previous = recorded_steps_top_eigenvectors[previous_step][:,:k]  # Previous top k eigenvectors\n",
    "            \n",
    "            for d in range(k):\n",
    "                \n",
    "                current_subspace = current[:, :k-d]  # Current subspace, top k-d eigenvectors\n",
    "                previous_subspace = previous[:, :k-d]  # Previous subspace, top k-d eigenvectors\n",
    "                \n",
    "                # Compute the similarity between the current and previous subspaces\n",
    "                matrix = np.matmul(current_subspace.T, previous_subspace)\n",
    "                _, sigma, _ = np.linalg.svd(matrix)\n",
    "                \n",
    "                # Check if all singular values are within [0, 1]\n",
    "                assert np.all((sigma >= -0.001) & (sigma <= 1.001)), \"Eigenvectors are not ortho-normalized!\"\n",
    "                \n",
    "                min_sigma = np.min(sigma)\n",
    "                \n",
    "                # If the minimal singular value is less then tau, then we reduce the dimensionality by d (one reduces dimension from top k to top k-d)\n",
    "                \n",
    "                # If the minimal singular value is greater than tau, which means the two subspaces are aligned, then we stop the loop and return the current k.\n",
    "                if min_sigma > tau:\n",
    "                    k = k-d\n",
    "                    break\n",
    "\n",
    "    return k\n",
    "\n",
    "k = Top_K_Search(recorded_steps_top_eigenvectors)\n",
    "\n",
    "print(k)    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Up Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import wandb\n",
    "\n",
    "def Top_K_Search(recorded_steps_top_eigenvectors):\n",
    "    \n",
    "    sorted_steps = sorted(recorded_steps_top_eigenvectors.keys())  # Epoch\n",
    "    num_steps = len(sorted_steps)\n",
    "    \n",
    "    if num_steps < 2:\n",
    "        raise ValueError(\"At least two recorded steps are required for Top-K search.\")\n",
    "    \n",
    "    # Initialize k\n",
    "    k = recorded_steps_top_eigenvectors[sorted_steps[0]].shape[1]  # Number of columns\n",
    "    # k = k_0\n",
    "    tau = 0.98 # Tolerance\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        current_step = sorted_steps[i]\n",
    "        current = recorded_steps_top_eigenvectors[current_step][:, :k]   # Current top k eigenvectors\n",
    "        if i > 0:\n",
    "            previous_step = sorted_steps[i - 1]\n",
    "            previous = recorded_steps_top_eigenvectors[previous_step][:,:k]  # Previous top k eigenvectors\n",
    "            \n",
    "            for d in range(k):\n",
    "                \n",
    "                current_subspace = current[:, :d+1]  # Current subspace\n",
    "                previous_subspace = previous[:, :d+1]  # Previous subspace\n",
    "                \n",
    "                # Compute the similarity between the current and previous subspaces\n",
    "                matrix = np.matmul(current_subspace.T, previous_subspace)\n",
    "                _, sigma, _ = np.linalg.svd(matrix)\n",
    "                \n",
    "                # Check if all singular values are within [0, 1]\n",
    "                assert np.all((sigma >= -0.001) & (sigma <= 1.001)), \"Eigenvectors are not ortho-normalized!\"\n",
    "                \n",
    "                # If the minimal singular value is less then tau, then we know that the two subspaces are not aligned, so we stop the loop and return the current k.\n",
    "                min_sigma = np.min(sigma)\n",
    "                \n",
    "                if min_sigma < tau:\n",
    "                    k = d\n",
    "                    break\n",
    "\n",
    "    return k\n",
    "\n",
    "k = Top_K_Search(recorded_steps_top_eigenvectors)\n",
    "\n",
    "print(k)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两个算法的主要区别是：\n",
    "\n",
    "Bottom-up Search: 从低维空间开始，逐渐增加维度，直到找到两个子空间的某个维度不\"对齐\"，即它们最小奇异值小于某个阈值（如0.98）。\n",
    "但是这个算法的要求很严格，举例来说：\n",
    "$$\n",
    "U = \\begin{bmatrix} \n",
    "u_1, u_2, \\dots, u_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "V = \\begin{bmatrix} \n",
    "v_1, v_2, \\dots, v_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "我们从第一维开始，即$d=0$, $u_1$ 和 $v_1$，如果它们不\"对齐\"，那么我们就停止，返回当前维度 $k=d=0$。反之，如果 $u_1$ 和 $v_1$ \"对齐\"，那么我们就继续增加维度，然后比较 $d=1$， $u_1, u_2$ 和 $v_1, u_2$ 是否对齐，直到找到某个维度不\"对齐\"为止， 此时返回 $k=d$ 。\n",
    "\n",
    "这个算法找到的 $k$ 满足以下性质:\n",
    "- 对于任意 $d \\leq k$， $u_1, u_2, \\dots, u_d$ 和 $v_1, v_2, \\dots, v_d$张成的子空间都是\"对齐\"的。\n",
    "\n",
    "Top-down Search: 从高维空间开始，逐渐减少维度，直到找到两个子空间\"对齐\"，即它们最小奇异值大于某个阈值（如0.98）。\n",
    "这个算法比较宽松，举例来说：\n",
    "$$\n",
    "U = \\begin{bmatrix} \n",
    "u_1, u_2, \\dots, u_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "V = \\begin{bmatrix} \n",
    "v_1, v_2, \\dots, v_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "我们从第 $m$ 维开始，即$k=m$, 考察 $u_1, \\dots, u_m$ 和 $v_1, \\dots, v_m$ 张成的子空间。如果它们对齐，即它们最小奇异值大于某个阈值（如0.98），那么就停止，返回当前维度。反之，如果它们不对齐，则减小维度，即$k=m-1$，考察 $u_1, \\dots, u_{m-1}$ 和 $v_1, \\dots, v_{m-1}$ 张成的子空间，直到找到某个维度对齐为止。\n",
    "\n",
    "这个算法找到的 $k$ 满足以下性质:\n",
    "- 对于 $dim=k$， $u_1, u_2, \\dots, u_k$ 和 $v_1, v_2, \\dots, v_k$ 张成的子空间是\"对齐\"的。\n",
    "- 但有可能发生对于某个 $d < k$， $u_1, u_2, \\dots, u_d$ 和 $v_1, v_2, \\dots, v_d$ 张成的子空间是 **\"不对齐\"** 的。\n",
    "\n",
    "因此这个算法比较宽松。我们要考察的是空间的整体性质，因此 Top-down Search 是可能是更好的选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m arr = [\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m11\u001b[39m]\n\u001b[32m     15\u001b[39m target = \u001b[32m7\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbinary_search_iterative\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# 输出 3\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mbinary_search_iterative\u001b[39m\u001b[34m(arr, target)\u001b[39m\n\u001b[32m      4\u001b[39m mid = left + (right - left) // \u001b[32m2\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr[mid] == target:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mid\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr[mid] > target:\n\u001b[32m      8\u001b[39m     right = mid - \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_4904d5__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_11instruction_6retval.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1144\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._return_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1247\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._stop_on_return\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1945\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Hessian/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2185\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2182\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2184\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2185\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2187\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2190\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Hessian/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2254\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2251\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2252\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2254\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2255\u001b[39m         notify_event.clear()\n\u001b[32m   2257\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Hessian/lib/python3.12/threading.py:634\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    632\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Hessian/lib/python3.12/threading.py:338\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    340\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def binary_search_iterative(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = left + (right - left) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] > target:\n",
    "            right = mid - 1\n",
    "        else:\n",
    "            left = mid + 1\n",
    "    return -1  # 未找到\n",
    "\n",
    "# 示例\n",
    "arr = [1, 3, 5, 7, 9, 11]\n",
    "target = 7\n",
    "print(binary_search_iterative(arr, target))  # 输出 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FakeMatrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, sigma, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     58\u001b[39m np.linalg.svd = fake_svd  \u001b[38;5;66;03m# 覆盖\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m s_found = \u001b[43mFirst_Step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecorded_steps_top_eigenvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m找到的 s =\u001b[39m\u001b[33m\"\u001b[39m, s_found)  \u001b[38;5;66;03m# 预期输出 2\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 恢复原始的 svd\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mFirst_Step\u001b[39m\u001b[34m(recorded_steps_top_eigenvectors)\u001b[39m\n\u001b[32m     13\u001b[39m mid = left + (right - left + \u001b[32m1\u001b[39m) // \u001b[32m2\u001b[39m  \u001b[38;5;66;03m# 取较大中点\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 这里取 mid+1 列，因为 mid 为 s-1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m matrix = np.matmul(\u001b[43mepoch_0\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mmid\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m.T, epoch_1[:, :mid+\u001b[32m1\u001b[39m])\n\u001b[32m     16\u001b[39m _, sigma, _ = np.linalg.svd(matrix)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 检查奇异值是否近似处于 [0, 1]\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'FakeMatrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def First_Step(recorded_steps_top_eigenvectors):\n",
    "    sorted_steps = sorted(recorded_steps_top_eigenvectors.keys())\n",
    "    epoch_0 = recorded_steps_top_eigenvectors[sorted_steps[0]]\n",
    "    epoch_1 = recorded_steps_top_eigenvectors[sorted_steps[1]]\n",
    "    \n",
    "    k_0 = epoch_0.shape[1]  # 列数，索引范围 0 到 k_0-1\n",
    "    \n",
    "    left, right = 0, k_0 - 1  # 搜索索引范围 s-1\n",
    "    \n",
    "    while left < right:\n",
    "        mid = left + (right - left + 1) // 2  # 取较大中点\n",
    "        # 这里取 mid+1 列，因为 mid 为 s-1\n",
    "        matrix = np.matmul(epoch_0[:, :mid+1].T, epoch_1[:, :mid+1])\n",
    "        _, sigma, _ = np.linalg.svd(matrix)\n",
    "        \n",
    "        # 检查奇异值是否近似处于 [0, 1]\n",
    "        assert np.all((sigma >= -0.001) & (sigma <= 1.001)), \"Eigenvectors are not ortho-normalized!\"\n",
    "    \n",
    "        if np.min(sigma) >= 0.98:\n",
    "            left = mid  # 当前 s = mid+1 满足条件，尝试更大 s\n",
    "        else:\n",
    "            right = mid - 1  # 当前 s 不满足，缩小范围\n",
    "            \n",
    "    return left + 1  # 返回实际列数 s\n",
    "\n",
    "# 模拟测试数据\n",
    "# 我们构造两个 3x4 矩阵，分别代表 epoch_0 和 epoch_1\n",
    "# 对于 s=1,2: 模拟奇异值为1.0；对于 s=3,4: 模拟奇异值低于阈值。\n",
    "# 这里我们通过硬编码的方式来模拟 SVD 返回的最小奇异值。\n",
    "\n",
    "class FakeMatrix:\n",
    "    def __init__(self, s):\n",
    "        self.s = s  # 列数\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return (3, self.s)\n",
    "\n",
    "# 构造两个字典，键为字符串，值为 FakeMatrix 实例\n",
    "recorded_steps_top_eigenvectors = {\n",
    "    'epoch1': FakeMatrix(4),\n",
    "    'epoch2': FakeMatrix(4)\n",
    "}\n",
    "\n",
    "# 重写 np.linalg.svd 来模拟不同 s 的情况\n",
    "original_svd = np.linalg.svd\n",
    "def fake_svd(matrix):\n",
    "    s = matrix.shape[0] if matrix.shape[0] < matrix.shape[1] else matrix.shape[1]\n",
    "    # 模拟 s=mid+1 的情况：如果 s <= 2, min sigma = 1.0; 如果 s >= 3, min sigma = 0.97.\n",
    "    if s <= 2:\n",
    "        sigma = np.ones(s)\n",
    "    else:\n",
    "        sigma = np.array([1.0]* (s - 1) + [0.97])\n",
    "    return None, sigma, None\n",
    "\n",
    "np.linalg.svd = fake_svd  # 覆盖\n",
    "\n",
    "s_found = First_Step(recorded_steps_top_eigenvectors)\n",
    "print(\"找到的 s =\", s_found)  # 预期输出 2\n",
    "\n",
    "# 恢复原始的 svd\n",
    "np.linalg.svd = original_svd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hessian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
